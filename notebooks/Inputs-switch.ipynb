{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loads = pd.read_csv('../data/clean/loads/HighLoads.csv')\n",
    "loads.head()\n",
    "loads['total'] = loads.sum(axis=1)\n",
    "loads.loc[loads['hour'] == 24, 'hour'] = 0\n",
    "loads.index = pd.to_datetime(loads[['year', 'month', 'day', 'hour']])\n",
    "last_year = loads.index.year[-1]\n",
    "loads.loc[loads['hour'] == 0].index += pd.DateOffset(day=1)\n",
    "#loads.loc[loads['year'] > last_year].index = loads.loc[loads['year'] > last_year].index.year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def get_load_data(path='../data/clean/loads', filename='HighLoads.csv', corrections=True, \n",
    "                  total=False, *args, **kwargs):\n",
    "    \"\"\" Load consumption data\n",
    "    \n",
    "    TODO:\n",
    "    This could be a csv or it could connect to a DB.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(path, filename))\n",
    "    # Calculate the sum of loads\n",
    "    df['total'] = df.sum(axis=1)\n",
    "    # Convert to datetime if does not exist\n",
    "    last_year = df['year'].iloc[-1:].values\n",
    "    if corrections:\n",
    "        try:\n",
    "            df.loc[df['hour'] == 24, 'hour'] = 0\n",
    "            df.loc[df['hour'] == 0, 'hour'] +=  1\n",
    "            # Fix below code to represent a year regression\n",
    "            df.loc[df['year'] > last_year] -= pd.DateOffset(day=365)\n",
    "        except ValueError as e:\n",
    "            # TODO Add error if data is wrong\n",
    "            pass\n",
    "    df.index = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "    \n",
    "    if total:\n",
    "        df = df[['total']].sort_index()\n",
    "    return df.sort_index()\n",
    "\n",
    "loads = get_load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timepoints creation\n",
    "\n",
    "This is the part where you can change the time resolution of switch. Here you can define the number of timepoints you will use for the analysis. One easy approach, to do it automatically is to groupb the data by maximum per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = loads.groupby([pd.TimeGrouper('A'), \n",
    "                                 pd.TimeGrouper('M')]).idxmax().add_suffix('_peakTime')\n",
    "timepoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `timepoints` dataframe we can get the number of timepoints that will be used and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Calculate the number of timepoints\n",
    "ts_num_tps = timepoints.groupby(level=[0]).size().unique()[0]\n",
    "ts_num_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = timepoints['total_peakTime']\n",
    "dates;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will recreate a full day considering the maximum of each month. We will obtain `n`number of points in front and behind the timestamp of the maximum load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_representative_day(data, dates, number=4):\n",
    "    \"\"\" Construc a representative day based on a single timestamp\n",
    "    \n",
    "    Args:\n",
    "    data\n",
    "    dates\n",
    "    number\n",
    "    Todo: Write readme\n",
    "    \"\"\"\n",
    "    years = []\n",
    "    if isinstance(dates, pd.Series):\n",
    "        for day in dates:\n",
    "            i_date = day - pd.DateOffset(hours=12)\n",
    "            f_date = day + pd.DateOffset(hours=12)\n",
    "            mask = (data.index >= i_date) & (data.index <= f_date)\n",
    "            # reset_index to preserve timepoint reference\n",
    "            years.append(data.loc[mask].iloc[::number].reset_index())\n",
    "    else:\n",
    "        i_date = dates - pd.DateOffset(hours=12)\n",
    "        f_date = dates + pd.DateOffset(hours=12)\n",
    "        mask = (data.index >= i_date) & (data.index <= f_date)\n",
    "        years.append(data.loc[mask].iloc[::number].reset_index())\n",
    "    output_data = pd.concat(years)\n",
    "    output_data.rename(columns={'index':'date'}, inplace=True)\n",
    "    return output_data\n",
    "\n",
    "output_data = get_representative_day(loads, dates[:6], number=7) \n",
    "# Fix the previous line bug (number = tps/day, dates = PeakTimeDay for the first \":#\" months)\n",
    "output_data = output_data.loc[output_data.date.dt.year <= 2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tab file\n",
    "\n",
    "### Timestamp\n",
    "\n",
    "The timestamp file needs to include the format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identifier = 'P'\n",
    "output_data['timestamp'] = output_data['date'].dt.strftime('%Y%m%d%H')\n",
    "output_data['TIMESERIES'] = output_data['date'].dt.strftime('%Y_%m{}'.format(identifier))\n",
    "output_data['daysinmonth'] = output_data['date'].dt.daysinmonth\n",
    "output_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timepoints_tab = output_data[['timestamp', 'TIMESERIES', 'daysinmonth']]\n",
    "timepoints_tab.index.name = 'timepoint_id'\n",
    "tmp = timepoints_tab.reset_index(drop=True)\n",
    "tmp = tmp.rename(columns={'TIMESERIES':'timeseries'})\n",
    "tmp.index += 1  # To start on 1\n",
    "tmp.index.name = 'timepoint_id'\n",
    "tmp[['timestamp', 'timeseries']].to_csv('switch-inputs/timepoints.tab', sep='\\t')\n",
    "tmp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Todo implement multiple periods based on the data\n",
    "d = OrderedDict({'INVESTMENT_PERIOD': [2016], 'period_start': [2015], 'period_end':[2025]})\n",
    "periods_tab = pd.DataFrame(d)\n",
    "periods_tab= periods_tab.set_index('INVESTMENT_PERIOD')\n",
    "periods_tab.to_csv('switch-inputs/periods.tab', sep='\\t')\n",
    "periods_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_tab = timepoints_tab[['TIMESERIES', 'daysinmonth']].drop_duplicates('TIMESERIES').reset_index(drop=True)\n",
    "ts_duration_of_tp = 6#(24/len(output_data))\n",
    "timeseries_tab['ts_period'] = 2016 # Fix this to change investment period\n",
    "timeseries_tab['count'] = timeseries_tab.groupby('ts_period')['TIMESERIES'].transform(len)\n",
    "timeseries_tab['ts_duration_of_tp'] = ts_duration_of_tp\n",
    "timeseries_tab['ts_num_tps'] = output_data[['timestamp', 'TIMESERIES']].groupby('TIMESERIES').count().values\n",
    "timeseries_tab['ts_scale_to_period'] = 10*24*(365/(timeseries_tab['count']))/(timeseries_tab['ts_duration_of_tp']*timeseries_tab['ts_num_tps'])\n",
    "timeseries_tab.index +=1\n",
    "timeseries_tab.index.name = 'timepoint_id'\n",
    "del timeseries_tab['daysinmonth']\n",
    "del timeseries_tab['count']\n",
    "timeseries_tab.to_csv('switch-inputs/timeseries.tab', index=False, sep='\\t')\n",
    "timeseries_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable capacity factor  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/clean/SWITCH/'\n",
    "ren_cap_data = pd.read_csv(data_path + 'ren-all.csv', index_col=0, parse_dates=True)\n",
    "ren_cap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_plants = len(ren_cap_data.GENERATION_PROJECT.unique())\n",
    "renewable_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren_cap_data_year = ren_cap_data.index.year.unique()\n",
    "ren_cap_data_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = set(output_data.date.dt.year)\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the generation using the filter dates\n",
    "filter_dates = pd.DatetimeIndex(output_data['date'].reset_index(drop=True))\n",
    "df = pd.DataFrame([])\n",
    "ren_tmp = ren_cap_data.copy()\n",
    "ren_tmp.index = ren_tmp.index + pd.DateOffset(years=2)\n",
    "#df = df.append(ren_tmp)\n",
    "for year in periods:\n",
    "    df = df.append(ren_tmp)\n",
    "    ren_tmp.index = ren_tmp.index + pd.DateOffset(years=1)\n",
    "grouped = df.loc[filter_dates].dropna().reset_index(drop=True).groupby('GENERATION_PROJECT', as_index=False)\n",
    "tmp = []\n",
    "for name, group in grouped:\n",
    "    tmp.append(group.reset_index(drop=True))\n",
    "variable_cap = pd.concat(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove(\"switch-inputs/variable_capacity_factors.tab\")\n",
    "variable_tab = variable_cap.groupby('GENERATION_PROJECT')\n",
    "for keys in variable_tab.groups.keys():\n",
    "    data = variable_tab.get_group(keys).reset_index(drop=True)\n",
    "    data.index +=1\n",
    "    data.index.name = 'timepoint'\n",
    "    data.rename(columns={'capacity_factor': 'gen_max_capacity_factor'},\n",
    "               inplace=True)\n",
    "    data.reset_index()[['GENERATION_PROJECT', 'timepoint', 'gen_max_capacity_factor']].to_csv('switch-inputs/variable_capacity_factors.tab', \n",
    "                                                                  sep='\\t', index=False, \n",
    "                mode='a', header=(not os.path.exists('switch-inputs/variable_capacity_factors.tab')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loads_tmp = loads[loads.year <= 2025]\n",
    "list_tmp = []\n",
    "tmp = (loads_tmp.loc[output_data['date']].drop(['year', 'month','day','hour', 'total'], axis=1).reset_index()\n",
    "        .drop_duplicates('index').reset_index(drop=True))\n",
    "del tmp['index']\n",
    "tmp = tmp.unstack(0)\n",
    "for name, group in tmp.groupby(level=0):\n",
    "    list_tmp.append(group.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab.index += 1\n",
    "loads_tab = loads_tab.rename(columns={'level_0':'LOAD_ZONE', 0:'zone_demand_mw'})\n",
    "del loads_tab['level_1']\n",
    "loads_tab.index.name = 'TIMEPOINT'\n",
    "loads_tab = loads_tab.reset_index()[['LOAD_ZONE', 'TIMEPOINT', 'zone_demand_mw']]\n",
    "loads_tab.to_csv('switch-inputs/loads.tab', sep='\\t', index=False)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
